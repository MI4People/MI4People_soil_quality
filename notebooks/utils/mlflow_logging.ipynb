{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9598e819",
   "metadata": {},
   "source": [
    "# How to use mlflow to log runs directly into s3 and an mysql-database\n",
    "For all functionality in src.models.mlflow_logging, you need to have a aws_credentials.yaml in the root of your project directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4361930",
   "metadata": {},
   "source": [
    "# Use Autolog for sklearn and pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3570e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 11:40:58 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An experiment with that name already exists, logging new run into it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 11:40:59 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e8938b6b096a4606b6441a7d823b2070', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2022/10/18 11:41:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Philip\\anaconda3\\envs\\mi4\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "# Imports for model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import mlflow\n",
    "\n",
    "# Import logging\n",
    "import src.models.mlflow_logging as ml_logging\n",
    "\n",
    "# This connects to s3 & the mysql-instance and starts an mlflow-experiment with the chosen name\n",
    "ml_logging.start_auto_logging(\"test_logging_local\", \"sklearn\")\n",
    "\n",
    "# Define some training data\n",
    "X = np.linspace(0, 1, 11)\n",
    "y = X * 2\n",
    "X = np.array([[x] for x in X])\n",
    "y = np.array([[i] for i in y])\n",
    "\n",
    "# Define a model for demo purposes\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# sklearn's autolog will log training metrics and model parameters automatically when calling fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# sklearns fit will not log anything\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "my_own_mse = float(sum([np.sqrt((i - j) ** 2) for i, j in zip(y_pred, y_test)]))\n",
    "# If you want to log other metrics which are not covered by autologging:\n",
    "mlflow.log_metric(\"my_own_mse\", my_own_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c810e07",
   "metadata": {},
   "source": [
    "# Alternative: Manual logging of run data\n",
    "Use this if you use a model library not directly supported by mlflow.\n",
    "Beware, this also creates a local mlflow folder and pickles the model locally, then uploads it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2055f50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An experiment with that name already exists, logging new run into it.\n"
     ]
    }
   ],
   "source": [
    "# For Manual logging (if you use a model library not directly supported by mlflow, create an experiment, start a run and log manually.\n",
    "\n",
    "# Imports for model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import mlflow\n",
    "import pickle\n",
    "\n",
    "# Import logging\n",
    "import src.models.mlflow_logging as ml_logging\n",
    "\n",
    "# Connect to AWS and create/set experiment\n",
    "ml_logging.create_or_set_experiment(\"test_logging_local_manual\")\n",
    "\n",
    "# Start a new run\n",
    "with mlflow.start_run():\n",
    "    # Define some training data\n",
    "    X = np.linspace(0, 1, 11)\n",
    "    y = X * 2\n",
    "    X = np.array([[x] for x in X])\n",
    "    y = np.array([[i] for i in y])\n",
    "\n",
    "    # Define a model for demo purposes\n",
    "    model = LinearRegression()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # This will not log anything without autologging\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Manual logging\n",
    "    my_own_mse = float(sum([np.sqrt((i - j) ** 2) for i, j in zip(y_pred, y_test)]))\n",
    "    mlflow.log_metric(\"my_own_mse\", my_own_mse)\n",
    "\n",
    "    # Log model by pickling (you could use mlflow.sklearn.log_model(model, \"model\"), but this cell is to show unsupported libraries)\n",
    "    with open(\"model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    mlflow.log_artifact(\"model.pkl\")\n",
    "\n",
    "    # Log params of your model\n",
    "    mlflow.log_param(\"Layers\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f42015",
   "metadata": {},
   "source": [
    "# Reading run data from the mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3764c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "credentials = ml_logging.get_aws_credentials()\n",
    "conn_str = f\"mysql+pymysql://{credentials['mysql']['user']}:{credentials['mysql']['password']}@mlflow-backend.chf6ry9cdkyl.eu-central-1.rds.amazonaws.com:3306/mlflowbackend\"\n",
    "\n",
    "# Calling the mlflow ui from here does not work.\n",
    "# subprocess.run([\"mlflow\", \"ui\", \"--backend-store-uri\", f\"mysql+pymysql://{credentials['mysql']['user']}:{credentials['mysql']['password']}@mlflow-backend.chf6ry9cdkyl.eu-central-1.rds.amazonaws.com:3306/mlflowbackend\"])\n",
    "\n",
    "# If you want to see the Mlflow ui to compare models, use this in your console:\n",
    "# mlflow ui --backend-store-uri connstr\n",
    "# To have access to artifacts in s3, you need to set your s3-credentials in a another credentials-file, as described in https://docs.aws.amazon.com/sdkref/latest/guide/file-location.html.\n",
    "# Calling \"mlflow ui\" does not use env-variables set in python, so ml_logging.set_s3_credentials() does not work here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mi4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dcf6f0f3d6451fd6b65c3a3dbdc0d32837fa77437fab6896a02635117e29a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
